# دانلود مورد از HCP

### نصب نرم افزار

```{python}
#| echo: true
!pip install boto3
```

### فراخونی کتابخانه‌های مهم

```{python}
#| echo: true
import boto3
import re
import os
import pandas as pd
from google.colab import drive
import shutil
```

```{python}
#| echo: true
drive.mount('/content/drive',force_remount=True)
# change directory to MyDrive(Google Drive's Folder)
# os.chdir("/content/drive/My Drive")
```

### تابع کمکی

```{python}
#| echo: true
def ensure_dir(file_path):
    directory = os.path.dirname(file_path)
    if not os.path.exists(directory):
        os.makedirs(directory)
```

### بارگذاری آیدی مورد‌ها از فایل اکسل در گوگل درایو

```{python}
#| echo: true
# Load the XLSX file into a DataFrame
df = pd.read_excel(
    'HCP_Drug_Users_ID.xlsx',
    sheet_name="hcp_tobacco_SSAGA_TB_DSM_Withdr"
)
```

### دانلود داده از سرور HCP با [s3 Amazon]{dir=ltr}

```{python}
#| echo: true
# s3 amazon acess key
access_key = '<YOUR-ACCESS-KEY>'
secret_key = '<YOUR-SECRET-KEY>'

# connecting to s1 amazon
s3_client = boto3.client(
    's3',
    aws_access_key_id=access_key, 
    aws_secret_access_key=secret_key
)
s3_resource = boto3.resource(
    's3',
    aws_access_key_id=access_key,
    aws_secret_access_key=secret_key
)

# create list of paths for downloading them
dataset = 'HCP_1200/'
nii_gz = "/MNINonLinear/Results/rfMRI_REST1_RL/rfMRI_REST1_RL.nii.gz"
s3_paths= [dataset+str(subject_id)+nii_gz for subject_id in df['Subject'].values]

print('Downloading starts ...')
s3 = boto3.client(
    's3',
    aws_access_key_id=access_key,
    aws_secret_access_key=secret_key
)

for key in s3_paths:
  print(key)
  path = key.replace('/', os.sep)
  ensure_dir(path)
  try:
    with open(path, 'wb') as data:
        s3.download_fileobj('hcp-openaccess', key, data)
  except:
    # remove the directory which was created for the downloading
    dir_remove=path.split('/')[:2]
    dir_remove='/'.join(dir_remove)
    shutil.rmtree(dir_remove)
    print('DATA DOSE NOT EXIST\n'+dir_remove)
print('Downloading finished')
```

